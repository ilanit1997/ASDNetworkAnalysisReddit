{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Data collection - Part 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your user name, client id, and client secret to create a read-only reddit instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-27T08:58:35.929269100Z",
     "start_time": "2023-05-27T08:58:35.840209800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import praw\n",
    "\n",
    "username = \"LaylaTheDog1997\"\n",
    "clientid = \"bRcb4hf7R9MnBXCl61N4NA\"\n",
    "clientsecret = \"SM0Itf82n7e_v7wBXF7mC-ypq7YT7g\"\n",
    "\n",
    "reddit = praw.Reddit(client_id=clientid,\n",
    "                     client_secret=clientsecret,\n",
    "                     user_agent='data collection (by {})'.format(username),\n",
    "                    redirect_uri='http://localhost:8000',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Retrieving and saving data - praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a search for key words in a specific subreddit or all of them.<br>\n",
    "\n",
    "For example let's serach for the phrase *I feel guilty* in all subreddits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-27T08:59:20.107098100Z",
     "start_time": "2023-05-27T08:59:05.834260500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "counter = 0\n",
    "posts_table = []\n",
    "column_names = [\"Index\", \"subreddit\", \"post_time\",\n",
    "                \"user_name\", \"title\", \"text\",\n",
    "                \"num_comments\", \"score\", \"ups\", \"upvote_ratio\", \n",
    "                \"downs\", 'downvote', \n",
    "                \"URL\",  \n",
    "               \"over18\"]\n",
    "\n",
    "subreddit = \"AutisticAdults\"\n",
    "results = reddit.subreddit(subreddit).new(limit=1000)\n",
    "for p in results: # p is a reddit post\n",
    "    counter += 1\n",
    "    # Add the post to the table\n",
    "    posts_table.append([counter, p.subreddit, datetime.utcfromtimestamp(p.created),\n",
    "                        p.author, p.title, p.selftext,\n",
    "                        p.num_comments, p.score, p.ups, p.upvote_ratio,\n",
    "                        p.downs, p.downvote,\n",
    "                        p.permalink\n",
    "                       , p.over_18])\n",
    "    \n",
    "\n",
    "posts_df = pd.DataFrame(posts_table, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posts_df.to_csv(\"postsASD.csv\", index=False) # index=False - do not save the default index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Save all user submisions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-27T09:01:18.788092100Z"
    }
   },
   "outputs": [],
   "source": [
    "users = posts_df['user_name'].unique()\n",
    "users = [u for u in users if u is not None]\n",
    "submission_comments_table = []\n",
    "column_names = [\"Index\", 'is_post',  \"subreddit\", \"post_time\",\n",
    "                \"user_name\", \"title\", \"text\",\n",
    "                \"num_comments\", \"score\", \"ups\", \"upvote_ratio\", \n",
    "                \"downs\", 'downvote', 'likes', \n",
    "                \"URL\",  \"over18\"]\n",
    "counter = 0\n",
    "\n",
    "for user in users:\n",
    "    submissions = user.submissions.new(limit=100)\n",
    "    for p in submissions:\n",
    "        if p.selftext in [\"\", \"[removed]\"]:\n",
    "            continue\n",
    "        counter += 1\n",
    "        submission_comments_table.append([counter, \"yes\", p.subreddit, datetime.utcfromtimestamp(p.created), \n",
    "                            p.author, p.title, p.selftext, \n",
    "                            p.num_comments, p.score, p.ups, p.upvote_ratio, \n",
    "                            p.downs, p.downvote,  p.likes,\n",
    "                            p.permalink,  p.over_18])\n",
    "posts_df_all = pd.DataFrame(posts_table, columns=column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posts_df_all.to_csv(\"postsASD_all.csv\", index=False) # index=False - do not save the default index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Loading the data to Pandas and basic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what can we learn from the data we retrieved.<br>\n",
    "\n",
    "First, we need to open the csv file we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subreddits_dict = {}\n",
    "subreddits = posts_df_all.subreddit.unique()\n",
    "for sub in subreddits:\n",
    "    users = posts_df_all[posts_df_all.subreddit == sub].user_name.unique()\n",
    "    subreddits_dict[sub] = users\n",
    "\n",
    "sorted_dict = dict(sorted(subreddits_dict.items(), key=lambda x: len(x[1]), reverse=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for k, v in sorted_dict.items():\n",
    "    if len(v) < 3:\n",
    "        continue\n",
    "    print(f\"subreddit = {k}, #users = {len(v)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_top_subreddits = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect neurotypical posts from top subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "counter = 0\n",
    "posts_table = []\n",
    "column_names = [\"Index\", \"subreddit\", \"post_time\",\n",
    "                \"user_name\", \"title\", \"text\",\n",
    "                \"num_comments\", \"score\", \"ups\", \"upvote_ratio\",\n",
    "                \"downs\", 'downvote',\n",
    "                \"URL\",\n",
    "               \"over18\"]\n",
    "\n",
    "for subreddit in filtered_top_subreddits:\n",
    "    results = reddit.subreddit(subreddit).new(limit=15)\n",
    "    for p in results: # p is a reddit post\n",
    "        if p.selftext in [\"\", \"[removed]\", \"[deleted]\"]:\n",
    "            continue\n",
    "        if p.author  in [\"[deleted]\"]:\n",
    "            continue\n",
    "        counter += 1\n",
    "        # Add the post to the table\n",
    "        posts_table.append([counter, p.subreddit, datetime.utcfromtimestamp(p.created),\n",
    "                            p.author, p.title, p.selftext,\n",
    "                            p.num_comments, p.score, p.ups, p.upvote_ratio,\n",
    "                            p.downs, p.downvote,\n",
    "                            p.permalink\n",
    "                           , p.over_18])\n",
    "\n",
    "\n",
    "posts_df_nr = pd.DataFrame(posts_table, columns=column_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "posts_df_nr.to_csv(\"postsNRTypical.csv\", index=False) # index=False - do not save the default index column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matching by subreddit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for subreddit in filtered_top_subreddits:\n",
    "    sub_df_nr = posts_df_nr[posts_df_nr.subreddit == subreddit]\n",
    "    sub_df_nr[\"ASD\"] = False\n",
    "    sub_df_asd = posts_df_all[posts_df_all.subreddit == subreddit]\n",
    "    sub_df_asd[\"ASD\"] = True\n",
    "    df_both = pd.concat([sub_df_asd, sub_df_asd], axis=0)\n",
    "    df_both.reset_index(inplace=True)\n",
    "    df_both.to_csv(os.path.join(\"posts\",f\"{subreddit}_both.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
